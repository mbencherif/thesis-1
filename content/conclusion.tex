% CONCLUSION AND OUTLOOK
%
%!TEX root = ../thesis-main.tex
%
%\part{Conclusion and outlook}
\chapter{Conclusion and outlook}
\label{chap:conclusion}

%\cleanchapterquote{You canâ€™t do better design with a computer, but you can speed up your work enormously.}{Wim Crouwel}{(Graphic designer and typographer)}

\section{Thesis summary}
 \label{sec:conclusion:summary}
 
 
 \TODO{here or in intro? or somewhere else?}
 This thesis project explores a variety of approaches to modeling the lexical stress prosody of native speech in such a way that the learner's utterance can be automatically compared to that native model. This investigation, and the creation of a CAPT tool that allows researchers to easily switch between different diagnostic approaches to study their effects, is one of the primary contributions of this work.

\section{Future work}
\label{sec:conclusion:future}


	\subsection{Evaluation of segmentation accuracy}
	
		\TODO{}

The accuracy of the forced-alignment segmentation can be assessed by computing inter-annotator agreement between the automatically produced segmentation and one or more manually-verified segmentations. The team at LORIA in Nancy has already completed this evaluation for the French IFCASL sub-corpus using the CoALT tool \citep{Fohr2012}. In cooperation with that team, the German sub-corpus (or a subset thereof) will be evaluated in the same way.
	A similar evaluation will be carried out for the syllable-level segmentations, a subset of which will be manually verified.

%	Error analysis will be performed for each boundary type, to enable identification of the types of boundaries at which the system tends (not) to make many errors. This detailed analysis will contribute to error management in the system, as described 
%in \cref{sec:segmentation:errors}.
%below.

	\subsection{Coping with segmentation errors}

	\TODO{}
	
		
	
	%ALREADY USED THIS SENTENCE IN DIAGNOSIS:Forced alignment is not a perfect method; because of the constraints put on the recognition system, the aligner will always find a match between the given text and audio, even if they do not correspond. 
	As mentioned in \cref{sec:diag:segmentation}, 
	Incorrect segmentation can lead to mistakes in diagnosis, so CAPT systems must have a means of reducing, or at least monitoring, the amount of error introduced by inaccurate segmentation \citep{Eskenazi2009}. 
	
	In the proposed CAPT tool, this function may be served by the development of a simple sentence- and/or word-level confidence measure. 
	While it is very difficult to compute such a measure directly from the decoding scores of the forced aligner, it may be possible to determine from the aforementioned accuracy evaluation which types of boundaries (e.g. between a sonorant and a vowel) the aligner typically has trouble detecting accurately, and then to calculate, for a given utterance, the proportion of error-prone boundaries. While a very simplistic measure, this could nevertheless provide some indication of when (not) to trust the automatic alignment, thus impacting decisions on how and whether to attempt error diagnosis (or feedback).
	% based on the boundary error rates found in \cref{sec:segmentation:eval}. 
	Other error-management strategies may also be explored, such as the type of error-filtering methods described by \textcite{Mesbahi2011,Bonneau2012,Orosanu2012}, in which utterances which do not correspond to the expected text are detected and rejected before alignment is attempted.
	
	
	
	
	\subsection{\TODO{Other}}
	
	\subsubsection{Pitch in Jsnoori}
	Soon to implement YIN \citep{Cheveigne2002} temporal method, and then combine results with those of Martin's or another spectral method such as SWIPE \citep{Camacho2007} (combining with NNs or something else)
	
	
	\subsubsection{Multiple references}
	Factors to explore in this approach might include whether the set of reference speakers should be more or less constrained (e.g. by gender), and which metrics can be used to synthesize the one-on-one comparisons into a single diagnosis.
	Alternatively, the learner's utterance could perhaps be compared directly with some unified representation of all the reference utterances; for example, if we represent each reference utterance as a point in n-dimensional space, with each dimension representing a relevant feature, the references will form a cluster which can serve as a representation of the variation permissible in native speech. By plotting the learner's utterance in the same space, it could be possible to distinguish how well (or poorly) this utterance fits into that cluster, and thereby produce a diagnosis.
	
	\subsubsection{Auto reference selection}
	.... speaker-dependent features of the speech of each reference candidate and of the learner -- possibly in their L1 (French) as well as the L2 (German) 
	
	 Relevant features may include.... spectral and duration-based features, and/or other features informed by research on speaker identification (e.g. \cite{Shriberg2005}). \TODO{examples of speaker ID features}
	 
	 \subsubsection{No-reference diagnosis}
	 
	 Other possibilities for generalized lexical stress modeling include using word-prosody predictions from a text-to-speech synthesizer such as MARY \citep{Schroeder2003}, as well as \TODO{fancier}
classification-based machine learning approaches 
%such as those used by \textcite{Shahin2012a,Kim2011} to categorize English words based on their stress patterns.