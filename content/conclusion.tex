% CONCLUSION AND OUTLOOK
%
%!TEX root = ../thesis-main.tex
%
%\part{Conclusion and outlook}
\chapter{Conclusion and outlook}
\label{chap:conclusion}

%\cleanchapterquote{You canâ€™t do better design with a computer, but you can speed up your work enormously.}{Wim Crouwel}{(Graphic designer and typographer)}

\section{Thesis summary}
 \label{sec:conclusion:summary}
 
 \TODO{\textit{remove} This thesis has presented a series of investigations of how Computer Assisted Pronunciation Training (CAPT) can help native (L1) speakers of French learning German as a nonnative language (L2) improve their pronunciation with respect to the prosodic realization of lexical stress. }
 %
 \TODO{Recap what lexical stress is}
 While lexical stress is a notoriously difficult phenomenon for L1 French speakers to come to terms with (see \cref{sec:stress:expected}), it is very important in German, and may have a large impact on the intelligibility of L2 German speech (see \cref{sec:targeting:intelligibility}). 
 In situations where language learners do not have access to 
 %individualized attention 
 %and corrective feedback 
% from 
a human German instructor, it is therefore advantageous to have CAPT tools which can automatically identify lexical stress errors in learners' L2 German utterances, and provide individualized corrective feedback on such errors to help learners overcome the hurdle this phenomenon presents. 
%
With this underlying motivation, this thesis has explored the ways in which lexical stress errors can be automatically diagnosed in learner speech, and a variety of methods for presenting learners with explicit and implicit feedback on these errors. 
 
% 
% Lexical stress errors are an ideal target for a CAPT system for such learners, because these errors fulfill the three criteria set out in \cref{sec:bkgd:targeting}:
% 
% 	\begin{itemize}
% 	\item{Lexical stress errors may have a large \textit{impact on intelligibility} in L2 German speech, as explained in \cref{sec:targeting:intelligibility}.}
% 	\item{There is a relatively high \textit{frequency of production} of lexical stress errors in the L2 German speech of L1 French speakers, especially among speakers of lower German proficiency levels, as attested by the analysis of learner errors presented in \cref{sec:lexstress:results}.}
% 	\item{The \textit{feasibility of automatic detection} of errors in lexical stress realization is encouraging; as described in \cref{sec:diag:classification}, an error classification system was developed in this work which is capable of detecting lexical stress errors at a level of accuracy comparable to the agreement between human annotators.}
% 	\end{itemize}
 
 
 \TODO{here or in intro? or somewhere else?}
 This thesis project explores a variety of approaches to modeling the lexical stress prosody of native speech in such a way that the learner's utterance can be automatically compared to that native model. This investigation, and the creation of a CAPT tool that allows researchers to easily switch between different diagnostic approaches to study their effects, is one of the primary contributions of this work.

\section{Future work}
\label{sec:conclusion:future}

\TODO{}


further work will be needed to shed light on whether the agreement differences observed among different word types might simply be a consequence of individual variation among the annotators assigned to each type, or whether other phenomena (e.g. frequency effects, segmental pronunciation errors, or interference from similar French words) might be at play.


	\subsection{Processing non-native speech}

	\subsubsection{Evaluation of segmentation accuracy}
	
		\TODO{}

The accuracy of the forced-alignment segmentation can be assessed by computing inter-annotator agreement between the automatically produced segmentation and one or more manually-verified segmentations. The team at LORIA in Nancy has already completed this evaluation for the French IFCASL sub-corpus using the CoALT tool \citep{Fohr2012}. In cooperation with that team, the German sub-corpus (or a subset thereof) will be evaluated in the same way.
	A similar evaluation will be carried out for the syllable-level segmentations, a subset of which will be manually verified.

%	Error analysis will be performed for each boundary type, to enable identification of the types of boundaries at which the system tends (not) to make many errors. This detailed analysis will contribute to error management in the system, as described 
%in \cref{sec:segmentation:errors}.
%below.

	\subsubsection{Coping with segmentation errors}

	\TODO{}
	
		
	
	%ALREADY USED THIS SENTENCE IN DIAGNOSIS:Forced alignment is not a perfect method; because of the constraints put on the recognition system, the aligner will always find a match between the given text and audio, even if they do not correspond. 
	As mentioned in \cref{sec:diag:segmentation}, 
	Incorrect segmentation can lead to mistakes in diagnosis, so CAPT systems must have a means of reducing, or at least monitoring, the amount of error introduced by inaccurate segmentation \citep{Eskenazi2009}. 
	
	In the proposed CAPT tool, this function may be served by the development of a simple sentence- and/or word-level confidence measure. 
	While it is very difficult to compute such a measure directly from the decoding scores of the forced aligner, it may be possible to determine from the aforementioned accuracy evaluation which types of boundaries (e.g. between a sonorant and a vowel) the aligner typically has trouble detecting accurately, and then to calculate, for a given utterance, the proportion of error-prone boundaries. While a very simplistic measure, this could nevertheless provide some indication of when (not) to trust the automatic alignment, thus impacting decisions on how and whether to attempt error diagnosis (or feedback).
	% based on the boundary error rates found in \cref{sec:segmentation:eval}. 
	Other error-management strategies may also be explored, such as the type of error-filtering methods described by \textcite{Mesbahi2011,Bonneau2012,Orosanu2012}, in which utterances which do not correspond to the expected text are detected and rejected before alignment is attempted.
	
	
	
	
	
	\subsubsection{Features of difficult-to-classify utterances}
	Would be a good idea to analyze the utterances that had low inter-annotator agreement (and those that were misclassified by the automatic system) to find features that differentiate ``clear'' utterances from ``unclear'' ones. (cf what \textcite{Michaux2013} plan to do)
	
	\subsubsection{Pitch in JSnoori}
	Soon to implement YIN \citep{Cheveigne2002} temporal method, and then combine results with those of Martin's or another spectral method such as SWIPE \citep{Camacho2007} (combining with NNs or something else)
	
	
	
	\subsection{Diagnosis}
	
	\subsubsection{Multiple references}
	Factors to explore in this approach might include whether the set of reference speakers should be more or less constrained (e.g. by gender), and which metrics can be used to synthesize the one-on-one comparisons into a single diagnosis.
	Alternatively, the learner's utterance could perhaps be compared directly with some unified representation of all the reference utterances; for example, if we represent each reference utterance as a point in n-dimensional space, with each dimension representing a relevant feature, the references will form a cluster which can serve as a representation of the variation permissible in native speech. By plotting the learner's utterance in the same space, it could be possible to distinguish how well (or poorly) this utterance fits into that cluster, and thereby produce a diagnosis.
	
	\subsubsection{Auto reference selection}
	.... speaker-dependent features of the speech of each reference candidate and of the learner -- possibly in their L1 (French) as well as the L2 (German) 
	
	 Relevant features may include.... spectral and duration-based features, and/or other features informed by research on speaker identification (e.g. \cite{Shriberg2005}). \TODO{examples of speaker ID features}
	 
	 \subsubsection{No-reference diagnosis}
	 
	 Other possibilities for generalized lexical stress modeling include using word-prosody predictions from a text-to-speech synthesizer such as MARY \citep{Schroeder2003}, as well as \TODO{fancier}
classification-based machine learning approaches 
%such as those used by \textcite{Shahin2012a,Kim2011} to categorize English words based on their stress patterns.
   ...online, semi-supervised learning which could allow the system to benefit from each new utterance recorded as a learner continues to use the system.
	


	\subsection{Feedback}
	
	\subsubsection{Mapping prosodic features to graphical properties}
	Shapes: To facilitate studies on which mappings, if any, make this feedback useful to the learner, the researcher-facing GUI should offer control over the different possible mappings.
	
	Text: As with the shapes mentioned above, and following \textcite{Sitaram2011}, it would be interesting to explore the possible mappings between acoustic features and properties of the text of each syllable (e.g. size, weight, underlining/decoration, etc.), with these mappings controllable by the researcher via the GUI.
	
	\subsubsection{Animation to convey pronunciation targets}
	...use of animation to transform the visualization of the learner's (incorrectly realized) utterance into a corresponding visualization of the correct realization, e.g. by growing or shrinking the size of the dot or text for each syllable to visualize the desired change in duration, or showing it moving up or down to convey the desired change in pitch.
	
	\subsubsection{Alternative prosodic modifications of learner speech}
	
	\begin{itemize}
	\item{Based on generalized contours instead of a concrete example - possible?}
	\item{Resynthesis of native reference utterance to emphasize/exaggerate stressed syllables, cf. \citep{Bissiri2006,Bissiri2009}}
	\end{itemize}