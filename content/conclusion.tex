% CONCLUSION AND OUTLOOK
%
%!TEX root = ../thesis-main.tex
%
%\part{Conclusion and outlook}
\chapter{Conclusion and outlook}
\label{chap:conclusion}

%\cleanchapterquote{You canâ€™t do better design with a computer, but you can speed up your work enormously.}{Wim Crouwel}{(Graphic designer and typographer)}

\section{Thesis summary}
 \label{sec:conclusion:summary}
 
 This thesis has presented a series of investigations of how Computer Assisted Pronunciation Training (CAPT) can help native (L1) speakers of French learning German as a nonnative language (L2) improve their pronunciation with respect to the prosodic realization of lexical stress.
 %
 Lexical stress, the phenomenon by which a given syllable is accorded a higher level of prominence than other syllables in a given word, serves a contrastive function in some languages (e.g. German) but not others (e.g. French).
 %While lexical stress is a notoriously difficult phenomenon for L1 French speakers to come to terms with (see \cref{sec:stress:expected}), it 
 Lexical stress is very important in German, and may have a large impact on the intelligibility of L2 German speech (see \cref{sec:targeting:intelligibility}); however, given that lexical stress is realized extremely differently (or not at all) in French (see \cref{sec:stress:french}), the correct prosodic realization of lexical stress in German is notoriously difficult for L1 French speakers (see \cref{sec:stress:expected}). 
 
 
%%%% LEXSTRESS 
 Indeed, analysis of lexical stress errors in a small corpus of L2 German words uttered by L1 French speakers, described in \cref{chap:lexstress}, seemed to confirm that such errors are frequent in the speech of these learners. On the whole, errors were observed in approximately one-third of learner utterances (see \cref{sec:results:overall}), though such errors were produced much more frequently by learners of lower German proficiency than those with more advanced skills (see \cref{sec:results:level}), with children making more errors than adult beginners (see \cref{sec:results:agegender}). 
 This evidence of a high frequency of production of lexical stress errors in the speech of such learners provides some justification for the selection of this type of error as the target of the prototype CAPT system developed in this work (see \cref{sec:targeting:frequency}).
 However, the analysis of such errors must take into account the fact that when asked to annotate lexical stress errors in learner utterances, human annotators of varying backgrounds with respect to L1 and phonetics/phonology expertise exhibited generally low agreement (see \cref{sec:lexstress:agreement}); this may indicate that identifying such errors in learner speech is not a straightforward task, and may involve an element of subjectivity. 
 If this is the case, it has important implications for treatment of such errors in CAPT, as reliable automatic detection is a requirement for a type of error to be addressed in a CAPT system (see \cref{sec:targeting:autodetect}), and the reliability of an automatic error diagnosis system should be evaluated in the context of the reliability of humans asked to perform the same task (see \cref{sec:classification:features}).
 
 
 
 
 The evident difficulty of correct realization of lexical stress for L1 French speakers, combined with its importance to intelligibility in L2 German, seem to imply that this phenomenon is a particularly important one for such learners to work on when seeking to improve their pronunciation.
 In situations where language learners do not have access to 
 %individualized attention 
 %and corrective feedback 
% from 
a human German instructor, it is therefore advantageous to have CAPT tools which can automatically identify lexical stress errors in learners' L2 German utterances, and provide individualized corrective feedback on such errors to help learners overcome the hurdle this phenomenon presents. 
%
With this underlying motivation, this thesis has explored the ways in which lexical stress errors can be automatically diagnosed in learner speech, and in which explicit and implicit feedback on these errors can be delivered to learners. It has also described the development of a prototype CAPT tool, \TODO{de-stress}, which implements these diverse diagnosis and feedback methods in a modular architecture, in the hopes of facilitating future research on which of these are most beneficial to learners in which contexts.


%%%% DIAGNOSIS
%
%This thesis project explores a variety of approaches to modeling the lexical stress prosody of native speech in such a way that the learner's utterance can be automatically compared to that native model. This investigation, and the creation of a CAPT tool that allows researchers to easily switch between different diagnostic approaches to study their effects, is one of the primary contributions of this work.
%
\Cref{chap:diagnosis} presented the approaches to diagnosis that have been explored in this thesis project and implemented in \TODO{de-stress}. All diagnosis starts from a prosodic analysis of the learner's utterance in terms of duration, fundamental frequency (F0), and intensity (see \cref{sec:diag:prosody}), based on a segmentation of that utterance produced automatically by forced alignment (see \cref{sec:diag:segmentation}). 
	In a comparison-based diagnostic approach, the prosody of the learner's utterance is then be compared to that of a reference (L1) utterance of the same word, and scored with respect to each of these three dimensions (see \cref{sec:compare:single}). 
	To capture the variability inherent in L1 pronunciations of the target word, comparison scores from multiple references can be combined (see \cref{sec:compare:multi}), and the best reference speaker(s) for a given learner can be chosen automatically to ensure the closest match possible between the learner's voice (F0) and that of the reference(s) (see \cref{sec:compare:selection}). 
	However, even when using multiple, intelligently selected reference speakers, the comparison-based approach potentially suffers from producing a diagnosis too closely linked to speaker- or utterance-dependent features of the reference(s). Therefore, an alternative diagnostic approach using classification by machine learning was investigated (see \cref{sec:diag:classification}). 
	Experiments with CART classifiers trained using different feature sets (see \cref{sec:classification:features}) revealed that duration features seem to be more useful for classification of L2 German stress errors than F0 features, which are in turn more useful than features representing intensity; however, the best results were obtained by  combining prosodic features with features capturing the word type uttered and the German proficiency level of the learner. 
	The overall agreement between the error diagnoses produced by the classifier and the gold-standard annotation being comparable to, if not slightly better than, the agreement observed between human annotators in the error annotation task, the results of these experiments seem encouraging with respect to the feasibility of reliable, automatic detection of such errors (see \cref{sec:classification:features:spkrword}). 
	Furthermore, the fact that utterances of word types which had been held out of the training data could be classified with only slightly lower accuracy (see \cref{sec:classification:unseen}) seems to \TODO{confirm} the potential of a classification-based approach to enable the creation of CAPT systems which are not limited to only those words/sentences for which recorded L1 utterances are available.
	\TODO{As the first known work using classification to diagnose lexical stress errors in the L2 German speech of L1 French speakers, these investigations constitute 
	a novel contribution
	%an important contribution of this thesis project 
	to research on German CAPT.}




%%%% FEEDBACK
%
As described in \cref{chap:feedback}, another important contribution of this work is an exploration of the various types of feedback that can be presented to the learner, based on a comparison- or classification-based diagnosis of the learner's utterance using one of the methods described in \cref{chap:diagnosis}. 
	Inspired by both classroom pronunciation teaching materials and existing prosody-aware CAPT systems, \TODO{de-stress} offers a diverse array of feedback options. Learners can be given implicit feedback on their pronunciation in the form of graphical or textual visual representations of the prosody of the given utterance(s) (see \cref{sec:implicit:visual}), and via the auditory channel through the playback of original and prosodically-modified utterances (see \cref{sec:implicit:auditory}
	Explicit feedback can also be delivered, in the form of skill bars visualizing pronunciation scores or verbal messages conveying the error(s) diagnosed and corrective suggestions (see \cref{sec:fb:explicit}).
	A simple web interface gives  instructors and researchers control over which feedback types are presented in a given exercise (see \cref{sec:fb:system}), thus making \TODO{de-stress} a valuable new tool for research into the comparative efficacy of various feedback types on pronunciation improvement, learner motivation, and other factors influencing the success of a CAPT system. 



%%%% CONCLUSION
%
\TODO{concluding paragraph}



%%% OLD
% 
% Lexical stress errors are an ideal target for a CAPT system for such learners, because these errors fulfill the three criteria set out in \cref{sec:bkgd:targeting}:
% 
% 	\begin{itemize}
% 	\item{Lexical stress errors may have a large \textit{impact on intelligibility} in L2 German speech, as explained in \cref{sec:targeting:intelligibility}.}
% 	\item{There is a relatively high \textit{frequency of production} of lexical stress errors in the L2 German speech of L1 French speakers, especially among speakers of lower German proficiency levels, as attested by the analysis of learner errors presented in \cref{sec:lexstress:results}.}
% 	\item{The \textit{feasibility of automatic detection} of errors in lexical stress realization is encouraging; as described in \cref{sec:diag:classification}, an error classification system was developed in this work which is capable of detecting lexical stress errors at a level of accuracy comparable to the agreement between human annotators.}
% 	\end{itemize}
 
 


\section{Future work}
\label{sec:conclusion:future}

\TODO{}


further work will be needed to shed light on whether the agreement differences observed among different word types might simply be a consequence of individual variation among the annotators assigned to each type, or whether other phenomena (e.g. frequency effects, segmental pronunciation errors, or interference from similar French words) might be at play.


	\subsection{Processing non-native speech}

	\subsubsection{Evaluation of segmentation accuracy}
	
		\TODO{}

The accuracy of the forced-alignment segmentation can be assessed by computing inter-annotator agreement between the automatically produced segmentation and one or more manually-verified segmentations. The team at LORIA in Nancy has already completed this evaluation for the French IFCASL sub-corpus using the CoALT tool \citep{Fohr2012}. In cooperation with that team, the German sub-corpus (or a subset thereof) will be evaluated in the same way.
	A similar evaluation will be carried out for the syllable-level segmentations, a subset of which will be manually verified.

%	Error analysis will be performed for each boundary type, to enable identification of the types of boundaries at which the system tends (not) to make many errors. This detailed analysis will contribute to error management in the system, as described 
%in \cref{sec:segmentation:errors}.
%below.

	\subsubsection{Coping with segmentation errors}

	\TODO{}
	
		
	
	%ALREADY USED THIS SENTENCE IN DIAGNOSIS:Forced alignment is not a perfect method; because of the constraints put on the recognition system, the aligner will always find a match between the given text and audio, even if they do not correspond. 
	As mentioned in \cref{sec:diag:segmentation}, 
	Incorrect segmentation can lead to mistakes in diagnosis, so CAPT systems must have a means of reducing, or at least monitoring, the amount of error introduced by inaccurate segmentation \citep{Eskenazi2009}. 
	
	In the proposed CAPT tool, this function may be served by the development of a simple sentence- and/or word-level confidence measure. 
	While it is very difficult to compute such a measure directly from the decoding scores of the forced aligner, it may be possible to determine from the aforementioned accuracy evaluation which types of boundaries (e.g. between a sonorant and a vowel) the aligner typically has trouble detecting accurately, and then to calculate, for a given utterance, the proportion of error-prone boundaries. While a very simplistic measure, this could nevertheless provide some indication of when (not) to trust the automatic alignment, thus impacting decisions on how and whether to attempt error diagnosis (or feedback).
	% based on the boundary error rates found in \cref{sec:segmentation:eval}. 
	Other error-management strategies may also be explored, such as the type of error-filtering methods described by \textcite{Mesbahi2011,Bonneau2012,Orosanu2012}, in which utterances which do not correspond to the expected text are detected and rejected before alignment is attempted.
	
	
	
	
	
	\subsubsection{Features of difficult-to-classify utterances}
	Would be a good idea to analyze the utterances that had low inter-annotator agreement (and those that were misclassified by the automatic system) to find features that differentiate ``clear'' utterances from ``unclear'' ones. (cf what \textcite{Michaux2013} plan to do)
	
	\subsubsection{Pitch in JSnoori}
	Soon to implement YIN \citep{Cheveigne2002} temporal method, and then combine results with those of Martin's or another spectral method such as SWIPE \citep{Camacho2007} (combining with NNs or something else)
	
	
	
	\subsection{Diagnosis}
	
	\subsubsection{Multiple references}
	Factors to explore in this approach might include whether the set of reference speakers should be more or less constrained (e.g. by gender), and which metrics can be used to synthesize the one-on-one comparisons into a single diagnosis.
	Alternatively, the learner's utterance could perhaps be compared directly with some unified representation of all the reference utterances; for example, if we represent each reference utterance as a point in n-dimensional space, with each dimension representing a relevant feature, the references will form a cluster which can serve as a representation of the variation permissible in native speech. By plotting the learner's utterance in the same space, it could be possible to distinguish how well (or poorly) this utterance fits into that cluster, and thereby produce a diagnosis.
	
	\subsubsection{Auto reference selection}
	.... speaker-dependent features of the speech of each reference candidate and of the learner -- possibly in their L1 (French) as well as the L2 (German) 
	
	 Relevant features may include.... spectral and duration-based features, and/or other features informed by research on speaker identification (e.g. \cite{Shriberg2005}). \TODO{examples of speaker ID features}
	 
	 \subsubsection{No-reference diagnosis}
	 
	 Produce individual dur/F0/int scores by using ensemble of different classifiers
	 
	 Other possibilities for generalized lexical stress modeling include using word-prosody predictions from a text-to-speech synthesizer such as MARY \citep{Schroeder2003}, as well as \TODO{fancier}
classification-based machine learning approaches 
%such as those used by \textcite{Shahin2012a,Kim2011} to categorize English words based on their stress patterns.
   ...online, semi-supervised learning which could allow the system to benefit from each new utterance recorded as a learner continues to use the system.
	


	\subsection{Feedback}
	
	\subsubsection{Mapping prosodic features to graphical properties}
	Shapes: To facilitate studies on which mappings, if any, make this feedback useful to the learner, the researcher-facing GUI should offer control over the different possible mappings.
	
	Text: As with the shapes mentioned above, and following \textcite{Sitaram2011}, it would be interesting to explore the possible mappings between acoustic features and properties of the text of each syllable (e.g. size, weight, underlining/decoration, etc.), with these mappings controllable by the researcher via the GUI.
	
	\subsubsection{Animation to convey pronunciation targets}
	...use of animation to transform the visualization of the learner's (incorrectly realized) utterance into a corresponding visualization of the correct realization, e.g. by growing or shrinking the size of the dot or text for each syllable to visualize the desired change in duration, or showing it moving up or down to convey the desired change in pitch.
	
	\subsubsection{Alternative prosodic modifications of learner speech}
	
	\begin{itemize}
	\item{Based on generalized contours instead of a concrete example - possible?}
	\item{Resynthesis of native reference utterance to emphasize/exaggerate stressed syllables, cf. \citep{Bissiri2006,Bissiri2009}}
	\end{itemize}